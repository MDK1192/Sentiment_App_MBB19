{
    "collab_server" : "",
    "contents" : "#\n# This is a Shiny web application. You can run the application by clicking\n# the 'Run App' button above.\n#\n# Find out more about building applications with Shiny here:\n#\n#    http://shiny.rstudio.com/\n#\nlibrary(shiny)\nlibrary(twitteR)\nlibrary(shinydashboard)\nlibrary(DT)\nlibrary(sentimentr)\nlibrary(SentimentAnalysis)\nlibrary(dplyr)\nlibrary(plotly)\nlibrary(tm)\nlibrary(lubridate)\nlibrary(readxl)\nlibrary(tidytext)\nlibrary(wordcloud) \nlibrary(lubridate)\nlibrary(ggplot2)\n\n\nui <- dashboardPage(\n  #Header Content\n  dashboardHeader(title = \"Sentiment-Dashboard\"),\n  \n  dashboardSidebar(\n    sidebarMenu(\n      menuItem(\"Landing Page\", tabName = \"landingpage\", icon = icon(\"th\")),\n      menuItem(\"Sentiment_Overview\", tabName = \"sentiment_overview\", icon = icon(\"th\")),\n      menuItem(\"Sentiment_Summarized\", tabName = \"sentiment_summarized\", icon = icon(\"th\")),\n      menuItem(\"Other Visualizations\", tabName = \"visualizations\", icon = icon(\"dashboard\"))\n    )\n  ),\n  \n  #Body Content\n  dashboardBody(\n    tabItems(\n      tabItem(tabName = \"landingpage\",\n              h2(\"Landing Page MBB19 Sentiment-Tool\"),\n              box(width = 12,\n                  box(width = 4, fileInput(\"file\", label = h3(\"Upload credentials in .xlsx Format\"))),\n                  box(width = 4,textInput(\"hashtag\", label = h3(\"Enter Twitter Hashtag\"), value = \"\")),\n                  box(width = 4,textInput(\"number\", label = h3(\"Enter Number of Tweets\"), value = \"\")),\n                  box(width = 12,dateRangeInput(\"dates\", label = h3(\"Select date range of Tweets\"), start = NULL, end = NULL))),\n              box(width = 12,\n                  box(width = 6, actionButton(\"loadButton\", label = \"Load Data\", width = '100%')),\n                  box(width = 6, actionButton(\"startButton\", label = \"Start Sentiment Analysis\", width = '100%'))),\n              box(width = 12,DTOutput(\"data_raw\"),title = \"Imported Data (Raw)\")\n      ),\n      tabItem(tabName = \"sentiment_overview\",\n              h2(\"Sentiments in Overview\"),\n              box(width = 12,DTOutput(\"data_clean\"),title = \"Imported Data (Cleaned)\"),\n              box(width = 12,DTOutput(\"sentiment_text\"),title = \"Sentiment Data\"),\n              box(width = 12,DTOutput(\"emotion_text\"),title = \"Emotion Data\")\n      ),\n      tabItem(tabName = \"sentiment_summarized\",\n              h2(\"Sentiments Summarized\"),\n              box(width = 12,plotOutput(\"polarity\")),\n              box(width = 12,plotOutput(\"emotionscount\")),\n              fluidRow(box(plotlyOutput(\"polaritydetail\", height = \"400px\", width = \"600px\")))\n              #box(width = 12,plotlyOutput(\"emotionsdetail\"))\n              ),\n      tabItem(tabName = \"visualizations\",\n              h2(\"Visualizations\"),\n              box(width = 12,\n                box(width = 6,plotOutput(\"wordcloud\")),\n                box(width = 6,plotOutput(\"wordcount\"))),\n              box(width = 12,plotOutput(\"timeplot\"))\n      )\n    )\n  )\n)\n\nserver <- function(input, output, session) {\n  #set options on loadcapacity for Twitter data\n  options(shiny.maxRequestSize=100*1024^2)\n  #get Twitter credentials and establish Connection\n  observeEvent(input$file, {\n    if(input$file != \"\"){\n      str(input$file)\n      #keys <- read_xlsx(\"Twitter_Credentials.xlsx\", col_names = T)\n      keys <- read_xlsx(input$file$datapath, col_names = T)\n      API_KEY <- as.character(keys$Twitter_Keys[1])\n      API_KEY_SECRET <- as.character(keys$Twitter_Keys[2])\n      ACCESS_TOKEN <- as.character(keys$Twitter_Keys[3])\n      ACCESS_TOKEN_SECRET <- as.character(keys$Twitter_Keys[4])\n      setup_twitter_oauth(API_KEY, API_KEY_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n    }\n  })\n  observeEvent(input$loadButton, {\n    #select correct constellation of entries\n    if(input$hashtag != \"\"){\n      if((input$dates[1] == input$dates[2])  && (input$number != \"\"))  data <- twListToDF(searchTwitter(paste0(input$hashtag, \" -filter:retweets\"), lang = \"en\", resultType = ,n = as.numeric(input$number)))\n      else if ((input$dates[1] != input$dates[2]) && (input$number == \"\")) data <- twListToDF(searchTwitter(paste0(input$hashtag, \" -filter:retweets\"), lang = \"en\", resultType = , since = as.character(input$dates[1]), until = as.character(input$dates[2])))\n      else if ((input$dates[1] != input$dates[2]) && (input$number != \"\")) data <- twListToDF(searchTwitter(paste0(input$hashtag, \" -filter:retweets\"), lang = \"en\", resultType = ,n = as.numeric(input$number), since = as.character(input$dates[1]), until = as.character(input$dates[2])))\n    }\n    else{\n      print(\"AAAA\")\n    }\n    data_demo <- data.frame(\"Date\" = as.character(data$created),\"Text\" = as.character(data$text))\n\n    output$data_raw <- renderDataTable(data_demo,options= list(scrollY = TRUE))\n\n    #create global data object for transfer\n    data_twitter <<- data\n    \n  })\n  observeEvent(input$startButton, {\n    \n    #start to clean data using a NLP-Pipeline approach\n    tweets_data <- data.frame(\"Text\"=data_twitter$text)\n    \n    #Take care of non-UTF-8 Characters, replace them with ''\n    iconv(tweets_data, \"UTF-8\", \"UTF-8\",sub='')\n    tweets_data$Text <- as.character(tweets_data$Text)\n    for(i in 1:nrow(tweets_data)){\n      tweets_data$Text[i] <- gsub(\"@\\\\w+ *\", \"\", tweets_data$Text[i])\n      Encoding(tweets_data$Text[i]) <- \"UTF-8\"\n    }\n    \n    #Normalize data (remove: Punctuation, Numbers, Capitalization, \"/()_-\", @XYZ, etc...)\n    tweets_data <- data.frame(\"Text\" = as.character(removePunctuation(removeNumbers(tolower(tweets_data$Text)))))\n    \n    tweets_data$Text <- as.character(tweets_data$Text)\n    \n    for(i in 1:nrow(tweets_data)){\n      tweets_data$Text[i] <- gsub(\"http\\\\w+ *\", \"\", tweets_data$Text[i])\n      tweets_data$Text[i] <- gsub(\"https\\\\w+ *\", \"\", tweets_data$Text[i])\n    }\n    output$data_clean <- renderDataTable(tweets_data,options= list(scrollY = TRUE))\n    \n    #Perform SentimentAnalysis while performing stemming and stopwords removal in-function-wise\n    sentiment_text <<- analyzeSentiment(tweets_data$Text, language = \"english\", removeStopwords = TRUE, stemming = TRUE)\n    emotion_text <- extract_emotion_terms(tweets_data$Text)\n    emotion_text <- emotion_text[,-c('element_id', 'sentence_id')]\n    output$sentiment_text <- renderDataTable(sentiment_text,options= list(scrollY = TRUE))\n    output$emotion_text <- renderDataTable(emotion_text,options= list(scrollY = TRUE))\n    #summarize the data\n    output$polarity <- renderPlot({\n      polarity <- mean(sentiment_text$SentimentGI, na.rm=T)\n      ggplot(data=sentiment_text, aes(sentiment_text$SentimentGI)) + \n        geom_histogram() +\n        geom_vline(xintercept = polarity, color = \"red\") +\n        labs(title = \"Overview over Polarity distribution of Tweets\", x = \"Polarity Score\")\n    })\n    output$polaritydetail <- renderPlotly({\n      #create dataset for visualization\n      pol_detail  <- sentiment_text\n      pol_detail$Tweet <- data_twitter$text\n      pol_detail <- arrange(pol_detail, desc(SentimentGI))\n      pol_detail$X <- c(1:nrow(pol_detail))\n      #visualize data\n      # ggplotly(ggplot(pol_detail, aes(x = X, y = SentimentGI, color = SentimentGI, text= Tweet)) +\n      #   geom_point() +\n      #   labs(title = \"Scatterplot of polarity of Tweets\"))\n      # # \n      #plot_ly(pol_detail, x = ~X, y = ~SentimentGI, color = ~SentimentGI, text= ~Tweet) %>% add_markers()\n      #ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) + geom_point()\n      plotly::plot_ly(iris, x = ~Sepal.Length, y = ~Sepal.Width, color = ~Species, type='scatter', mode = 'markers')\n      plot_ly(x = 1:10, y = 1:10)\n      # Plot1 <- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) + geom_point()\n      # Plot1 <- plotly_build(Plot1)\n      # # Plot1$x$layout$margin$l <- 180\n      # Plot1 <- ggplotly(Plot1)\n      # Plot1\n      #plot1 <- plot_ly(iris, x = ~Sepal.Length, y = ~Sepal.Width, color = ~Species, type = \"scatter\", mode =\"markers\")\n      \n    })\n    \n    output$emotionsdetail <- renderPlotly({\n      e <<- emotion_text\n      # ggplot(data=sentiment_text, aes(sentiment_text$SentimentGI)) + \n      #   geom_histogram() +\n      #   geom_vline(xintercept = polarity, color = \"red\") +\n      #   labs(title = \"Overview over Polarity distribution of Tweets\", x = \"Polarity Score\")\n      # \n      \n      \n    })\n    output$emotionscount <- renderPlot({\n      emotions<- na_if(emotion_text[,c(1:8)], \"character(0)\")\n      emotions_consolidated <- as.data.frame(t(data.frame(\"anger\"=sum(!is.na(emotions$anger)),\n                                          \"anticipation\"=sum(!is.na(emotions$anticipation)),\n                                          \"disgust\"=sum(!is.na(emotions$disgust)),\n                                          \"fear\"=sum(!is.na(emotions$fear)),\n                                          \"joy\"=sum(!is.na(emotions$joy)),\n                                          \"sadness\"=sum(!is.na(emotions$sadness)),\n                                          \"surprise\"=sum(!is.na(emotions$surprise)),\n                                          \"trust\"=sum(!is.na(emotions$trust)))))\n      ggplot(emotions_consolidated, aes(x=reorder(row.names(emotions_consolidated), as.numeric(V1)), y=as.numeric(V1))) +\n        geom_bar(stat=\"identity\") +\n        coord_flip() +\n        labs(title = \"Overview over Emotions\", x= \"Emotion\",  y= \"Frequency\")\n    })\n    output$wordcloud <- renderPlot({\n      wordcount_vec <- c()\n      for(i in 1:nrow(tweets_data)){\n        wordcount_vec <- paste0(wordcount_vec, tweets_data$Text[i])\n      }\n      wordcount_vec <- strsplit(wordcount_vec, \" \")\n      wordcounts <- data.frame(table(wordcount_vec))\n      wordcounts <- wordcounts[wordcounts$wordcount_vec != \"\",]\n      wordcloud(words = wordcounts$wordcount_vec, freq = wordcounts$Freq, min.freq = 5, max.words=100, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, \"Dark2\"))\n    })\n    output$wordcount <- renderPlot({\n      wordcount_vec <- c()\n      for(i in 1:nrow(tweets_data)){\n        wordcount_vec <- paste0(wordcount_vec, tweets_data$Text[i])\n      }\n      wordcount_vec <- strsplit(wordcount_vec, \" \")\n      wordcounts <- data.frame(table(wordcount_vec))\n      wordcounts <- wordcounts[wordcounts$Freq > 15,]\n      wordcounts <- wordcounts[wordcounts$wordcount_vec != \"\",]\n      ggplot(wordcounts, aes(x=reorder(wordcount_vec, as.numeric(Freq)), y=as.numeric(Freq))) +\n        geom_bar(stat=\"identity\") +\n        coord_flip() +\n        labs(title = \"Overview over most common Words\", x= \"Word\",  y= \"Frequency\")\n    })\n    output$timeplot <- renderPlot({\n      diff_mins <- as.numeric(difftime(as.POSIXlt(Sys.time(),tz=\"UTC\"),data_twitter$created, \"mins\"))\n      diff_mins_df <- as.data.frame(table(droplevels(as.data.frame(cut(diff_mins, breaks = seq(0, 180, by = 5))))))\n      ggplot(diff_mins_df, aes(x = Var1, y= as.numeric(Freq), group=1)) +\n        geom_point() +\n        geom_line() +\n        labs(title = \"Overview Tweet frequency in the last 3 Hours\",x = \"Minutes from Now\", y=\"Frequency\")\n    })\n  })\n}\n\n\n# ggplot(data, aes(x = main_genre)) +\n#   geom_bar() +\n#   coord_flip() + \n#   facet_wrap(~decade) +\n#   labs(title = \"Overview over Genre Frequency over the decades\",\n#        x = \"Genre\")\n\n\n#https://www.aclweb.org/anthology/L18-1030.pdf\n\n\n#IMDB Movie Reviews Dataset\n\n#This large movie dataset contains a collection of about 50,000 movie reviews from IMDB. In this dataset, only highly polarised reviews are being considered. The positive and negative reviews are even in number; however, the negative review has a score of ≤ 4 out of 10, and the positive review has a score of ≥ 7 out of 10.\n\n\n\nshinyApp(ui, server)\n\n\n\n",
    "created" : 1588951120990.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "542097801",
    "id" : "FAF50FD7",
    "lastKnownWriteTime" : 1589224768,
    "last_content_update" : 1589224768490,
    "path" : "~/SemiStruk_MBB19/SemiStruk_MBB19/app.R",
    "project_path" : "SemiStruk_MBB19/app.R",
    "properties" : {
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}